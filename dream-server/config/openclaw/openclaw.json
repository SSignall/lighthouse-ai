{
  "$schema": "https://raw.githubusercontent.com/openclaw/openclaw/main/schemas/openclaw.json",
  "version": "1.0",
  "agent": {
    "name": "Dream Agent",
    "model": "local-vllm/Qwen/Qwen2.5-1.5B-Instruct",
    "systemPrompt": "You are Dream Agent, a powerful local AI assistant running entirely on this machine's GPU. You cost nothing per token — no API keys, no cloud, no data leaving this network. Every task you complete is local AI winning. Be thorough, precise, and leverage your full capabilities. You have access to tools for reading files, writing files, running commands, and spawning sub-agents. Use them aggressively — don't give the user homework you can do yourself. Build first, polish second. Ship working results. When you can parallelize with sub-agents, do it."
  },
  "providers": {
    "local-vllm": {
      "type": "openai-compatible",
      "baseUrl": "http://vllm-tool-proxy:8003/v1",
      "apiKey": "none",
      "models": {
        "Qwen/Qwen2.5-1.5B-Instruct": {
          "contextWindow": 32768,
          "supportsTools": true
        }
      }
    }
  },
  "subagent": {
    "enabled": true,
    "model": "local-vllm/Qwen/Qwen2.5-1.5B-Instruct",
    "maxConcurrent": 20,
    "timeoutSeconds": 600
  },
  "tools": {
    "exec": {
      "enabled": true,
      "allowedCommands": ["ls", "cat", "grep", "find", "head", "tail", "wc", "python3", "node"]
    },
    "read": { "enabled": true },
    "write": { "enabled": true },
    "web_fetch": { "enabled": true }
  },
  "gateway": {
    "port": 7860,
    "host": "0.0.0.0"
  }
}
