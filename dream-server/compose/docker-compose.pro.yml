# Dream Server — Pro Tier
# 24GB+ VRAM — 32B models, full voice stack
# Usage: docker compose -f docker-compose.pro.yml up -d

services:
  # ═══════════════════════════════════════════════════════════════
  # LLM — Qwen2.5-32B-Instruct-AWQ
  # ═══════════════════════════════════════════════════════════════
  vllm:
    image: vllm/vllm-openai:v0.15.1
    runtime: nvidia
    container_name: dream-vllm
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - VLLM_ATTENTION_BACKEND=FLASHINFER
    volumes:
      - ${HF_HOME:-~/.cache/huggingface}:/root/.cache/huggingface
    ports:
      - "8000:8000"
    command: >
      --model Qwen/Qwen2.5-32B-Instruct-AWQ
      ${VLLM_QUANTIZATION:+--quantization $VLLM_QUANTIZATION}
      --max-model-len 32768
      --gpu-memory-utilization 0.90
      --enable-auto-tool-choice
      --tool-call-parser hermes
      --served-model-name gpt-4o
      --trust-remote-code
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 300s
    restart: unless-stopped

  # ═══════════════════════════════════════════════════════════════
  # STT — Whisper Large v3
  # ═══════════════════════════════════════════════════════════════
  whisper:
    image: fedirz/faster-whisper-server:latest-cuda
    runtime: nvidia
    container_name: dream-whisper
    environment:
      - WHISPER__MODEL=Systran/faster-whisper-large-v3
      - WHISPER__DEVICE=cuda
      - NVIDIA_VISIBLE_DEVICES=all
    ports:
      - "8001:8000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # ═══════════════════════════════════════════════════════════════
  # TTS — Kokoro (GPU-accelerated)
  # ═══════════════════════════════════════════════════════════════
  kokoro:
    image: ghcr.io/remsky/kokoro-fastapi:v0.6.2-gpu
    runtime: nvidia
    container_name: dream-kokoro
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    ports:
      - "8880:8880"
    volumes:
      - kokoro-cache:/app/cache
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8880/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # ═══════════════════════════════════════════════════════════════
  # LiveKit — WebRTC Server
  # ═══════════════════════════════════════════════════════════════
  livekit:
    image: livekit/livekit-server:latest
    container_name: dream-livekit
    ports:
      - "7880:7880"   # HTTP
      - "7881:7881"   # WebRTC TCP
      - "7882:7882/udp"  # WebRTC UDP
    command: >
      --config /livekit.yaml
    volumes:
      - ./livekit.yaml:/livekit.yaml:ro
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:7880"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: unless-stopped

  # ═══════════════════════════════════════════════════════════════
  # Voice Agent — Connects LLM + STT + TTS via LiveKit
  # ═══════════════════════════════════════════════════════════════
  voice-agent:
    build:
      context: ./agents/voice
      dockerfile: Dockerfile
    container_name: dream-voice-agent
    environment:
      - LIVEKIT_URL=ws://livekit:7880
      - LIVEKIT_API_KEY=${LIVEKIT_API_KEY:?LIVEKIT_API_KEY must be set}
      - LIVEKIT_API_SECRET=${LIVEKIT_API_SECRET:?LIVEKIT_API_SECRET must be set}
      - LLM_BASE_URL=http://vllm:8000/v1
      - STT_BASE_URL=http://whisper:8000
      - TTS_BASE_URL=http://kokoro:8880
    depends_on:
      vllm:
        condition: service_healthy
      whisper:
        condition: service_healthy
      kokoro:
        condition: service_healthy
      livekit:
        condition: service_healthy
    restart: unless-stopped

  # ═══════════════════════════════════════════════════════════════
  # Dashboard — Web UI
  # ═══════════════════════════════════════════════════════════════
  dashboard:
    build:
      context: ./dashboard
      dockerfile: Dockerfile
    container_name: dream-dashboard
    ports:
      - "3001:3001"
    environment:
      - VITE_API_URL=http://localhost:3002
      - VITE_LIVEKIT_URL=ws://localhost:7880
    depends_on:
      - api
    restart: unless-stopped

  # ═══════════════════════════════════════════════════════════════
  # API — Backend for Dashboard
  # ═══════════════════════════════════════════════════════════════
  api:
    build:
      context: ./dashboard-api
      dockerfile: Dockerfile
    container_name: dream-api
    ports:
      - "3002:3002"
    environment:
      - VLLM_URL=http://vllm:8000
      - WHISPER_URL=http://whisper:8000
      - KOKORO_URL=http://kokoro:8880
      - LIVEKIT_URL=ws://livekit:7880
      - LIVEKIT_API_KEY=${LIVEKIT_API_KEY:?LIVEKIT_API_KEY must be set}
      - LIVEKIT_API_SECRET=${LIVEKIT_API_SECRET:?LIVEKIT_API_SECRET must be set}
    depends_on:
      - vllm
    restart: unless-stopped

volumes:
  kokoro-cache:
